{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct agent\n",
    "\n",
    "1. create_react_agent: (one that creates the agent)\n",
    "\n",
    "Takes each tool name and description\n",
    "Formats them into a standardized way the LLM can understand\n",
    "Inserts them into a specific placeholders in the react prompt template\n",
    "it makes the LLM call + takes the LLM response and parses the response to one of this two classes `AgentAction`, `AgentFinish`.\n",
    "\n",
    "`AgentAction`: This is a LangChain class that represents an action the agent wants to take. It typically contains:\n",
    " ```\n",
    "   action = AgentAction(\n",
    "    tool='calculator'\n",
    "    tool_input='2+3'\n",
    "    log= 'I need you to calculate the sum of 2 + 3'\n",
    "   )\n",
    " ```\n",
    " this consists of the thought, action and observation. \n",
    "\n",
    " `AgentFinish`: Incase the LLM doesnt have to call any tool this is the final call and contains the final answer.\n",
    "\n",
    " ```\n",
    "  finish = AgentFinish(\n",
    "    return_values={\"output\": \"The ans is 5\"}\n",
    "    log= \"I've calculate the sum of 2+3 and the answer is 5\"\n",
    "  )\n",
    " ```\n",
    "\n",
    " 2. AgentExecutor: \n",
    "\n",
    " It takes the agent from create_react_agent and manages the execution loop.\n",
    " Recieves the user's question and feeds it to the agent\n",
    " Identifies which tool to run based on the agents output(AgentAction or No tool if AgentFinish)\n",
    " Executes the tool and captures the result\n",
    " Feeds the result back to the agent for the next decision\n",
    " continues this loop until AgentFinish\n",
    " Returns the final answer to the user\n",
    "\n",
    "\n",
    " # Key advantages of using LangGraph\n",
    "\n",
    " LangGraph turns the hidden 'black-box' loop into a visible, editable workflow\n",
    "\n",
    " Start-> reason_node --->act_node \n",
    "            |              <-|\n",
    "            v \n",
    "           End\n",
    "\n",
    "The reason_node now does what create_react_agent did. It thinks and decides.\n",
    "if the reason_node outputs an agentAction then act node executes the tool, The\n",
    "results flow back to reason node for the next decision.\n",
    "When the agent has the final answer, It takes the right path to end\n",
    "This makes the black box of the agentExecutor transparent and modifiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reason node\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import tool, create_react_agent\n",
    "import datetime\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain import hub\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "\n",
    "@tool\n",
    "def get_current_system_time(format: str = \"%Y-%m-%d %H:%M:%S\") -> str:\n",
    "    \"\"\" Returns the current date and time in the specified format \"\"\"\n",
    "    import datetime\n",
    "    # Get the current system time\n",
    "    current_time = datetime.datetime.now()\n",
    "    # Format the time as a string\n",
    "    formatted_time = current_time.strftime(format)\n",
    "    return formatted_time\n",
    "\n",
    "search_tool = TavilySearchResults(search_depth=\"basic\")\n",
    "tools = [search_tool, get_current_system_time]\n",
    "react_prompt = hub.pull(\"hwchase17/react\")\n",
    "react_agent_runnable = create_react_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    prompt=react_prompt\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# react state\n",
    "from typing import TypedDict, Annotated, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    agent_outcome: Union[AgentAction, AgentFinish, None]\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def reason_node(state: AgentState):\n",
    "    agent_outcome = react_agent_runnable.invoke(state)\n",
    "    return{\"agent_outcome\": agent_outcome}\n",
    "\n",
    "def act_node(state: AgentState):\n",
    "    agent_action = state[\"agent_outcome\"]\n",
    "    # extract tool name and input from AgentAction\n",
    "    tool_name = agent_action.tool\n",
    "    tool_input = agent_action.tool_input\n",
    "    tool_function = None\n",
    "    for tool in tools:\n",
    "        if tool.name == tool_name:\n",
    "            tool_function = tool\n",
    "            break\n",
    "    \n",
    "    if tool_function:\n",
    "        if isinstance(tool_input, dict):\n",
    "            output = tool_function.invoke(**tool_input)\n",
    "        else:\n",
    "            output = tool_function.invoke(tool_input)\n",
    "    else:\n",
    "        output = f\"Tool '{tool_name}' not found\"\n",
    "    return{\"intermediate_steps\":[(agent_action, str(output))]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'How many days ago was the latest SpaceX launch?', 'agent_outcome': AgentAction(tool='get_current_system_time', tool_input=\"'%Y-%m-%d'\", log=\"To answer the question of how many days ago the latest SpaceX launch occurred, I need to find the date of the most recent SpaceX launch and then compare it to today's date. \\n\\nAction: get_current_system_time\\nAction Input: '%Y-%m-%d'\"), 'intermediate_steps': [(AgentAction(tool='get_current_system_time', tool_input=\"'%Y-%m-%d'\", log=\"To answer the question of how many days ago the latest SpaceX launch occurred, I need to find the date of the most recent SpaceX launch and then compare it to today's date. \\n\\nAction: get_current_system_time\\nAction Input: '%Y-%m-%d'\"), \"'2025-06-20'\")]} result---\n",
      "Agent is still reasoning, or returned an intermediate action: tool='get_current_system_time' tool_input=\"'%Y-%m-%d'\" log=\"To answer the question of how many days ago the latest SpaceX launch occurred, I need to find the date of the most recent SpaceX launch and then compare it to today's date. \\n\\nAction: get_current_system_time\\nAction Input: '%Y-%m-%d'\"\n"
     ]
    }
   ],
   "source": [
    "# graph\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.agents import AgentFinish, AgentAction\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "REASON_NODE = \"reason_node\"\n",
    "ACT_NODE = \"act_node\"\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    if isinstance(state[\"agent_outcome\"], AgentFinish):\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        return END\n",
    "    else:\n",
    "      return ACT_NODE\n",
    "\n",
    "\n",
    "graph = StateGraph(state_schema=AgentState)\n",
    "\n",
    "graph.add_node(REASON_NODE, reason_node)\n",
    "graph.add_node(ACT_NODE, act_node)\n",
    "graph.set_entry_point(REASON_NODE)\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    REASON_NODE,\n",
    "    should_continue\n",
    ")\n",
    "\n",
    "graph.add_edge(REASON_NODE, ACT_NODE)\n",
    "app = graph.compile()\n",
    "result = app.invoke(\n",
    "    {\n",
    "        \"input\": \"How many days ago was the latest SpaceX launch?\", \n",
    "        \"agent_outcome\": None, \n",
    "        \"intermediate_steps\": []\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result, 'result---')\n",
    "# print(result[\"agent_outcome\"].return_values[\"output\"], \"final result\")\n",
    "\n",
    "agent_outcome = result[\"agent_outcome\"]\n",
    "\n",
    "if hasattr(agent_outcome, \"return_values\"):\n",
    "    print(agent_outcome.return_values[\"output\"], \"final result\")\n",
    "else:\n",
    "    print(\"Agent is still reasoning, or returned an intermediate action:\", agent_outcome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
